{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199569c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded C:\\Users\\KIIT\\Desktop\\VS_Code\\GitHub\\Major_Project\\model_artifacts\\maternal_best_rf.joblib\n",
      "Loaded C:\\Users\\KIIT\\Desktop\\VS_Code\\GitHub\\Major_Project\\model_artifacts\\maternal_xgboost.joblib\n",
      "Loaded C:\\Users\\KIIT\\Desktop\\VS_Code\\GitHub\\Major_Project\\model_artifacts\\maternal_scaler.joblib\n",
      "Loaded C:\\Users\\KIIT\\Desktop\\VS_Code\\GitHub\\Major_Project\\model_artifacts\\ctg_randomforest_model.joblib\n",
      "Loaded C:\\Users\\KIIT\\Desktop\\VS_Code\\GitHub\\Major_Project\\model_artifacts\\ctg_xgboost_model.joblib\n",
      "Loaded C:\\Users\\KIIT\\Desktop\\VS_Code\\GitHub\\Major_Project\\model_artifacts\\ctg_scaler.joblib\n",
      "Loaded C:\\Users\\KIIT\\Desktop\\VS_Code\\GitHub\\Major_Project\\model_artifacts\\fetal_ecg_lstm_model.h5\n",
      "Loaded C:\\Users\\KIIT\\Desktop\\VS_Code\\GitHub\\Major_Project\\model_artifacts\\fetal_ultrasound_classifier.h5\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Required variables X_resampled, X_test_scaled, y_resampled, y_true must exist in the notebook.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 100\u001b[0m\n\u001b[0;32m     97\u001b[0m y_test_tab \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mglobals\u001b[39m()\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# y_true is maternal test labels exposed in notebook\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X_train_tab \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m X_test_tab \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m y_train_tab \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m y_test_tab \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 100\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequired variables X_resampled, X_test_scaled, y_resampled, y_true must exist in the notebook.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# Compute per-model probabilities and concatenate\u001b[39;00m\n\u001b[0;32m    103\u001b[0m train_probas_parts \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Required variables X_resampled, X_test_scaled, y_resampled, y_true must exist in the notebook."
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Multimodal late-fusion / stacking demo\n",
    "# Saves a meta-classifier that learns from per-modality model probabilities.\n",
    "# Assumes maternal models were trained on X_resampled/X_test_scaled (variables exist in notebook).\n",
    "# If other modality inputs are available and aligned (CTG, ECG LSTM, Ultrasound), extend the predict_* functions and\n",
    "# include their probability outputs when building train/test feature matrices.\n",
    "\n",
    "\n",
    "# --- load saved models (skip if not present) ---\n",
    "loaded = {}\n",
    "def try_joblib(path, key):\n",
    "    try:\n",
    "        loaded[key] = joblib.load(path)\n",
    "        print(f\"Loaded {path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Skip loading {path}: {e}\")\n",
    "\n",
    "def try_keras(path, key):\n",
    "    try:\n",
    "        loaded[key] = load_model(path, compile=False)\n",
    "        print(f\"Loaded {path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Skip loading {path}: {e}\")\n",
    "\n",
    "try_joblib(r\"C:\\Users\\KIIT\\Desktop\\VS_Code\\GitHub\\Major_Project\\model_artifacts\\maternal_best_rf.joblib\", \"maternal_best_rf\")\n",
    "try_joblib(r\"C:\\Users\\KIIT\\Desktop\\VS_Code\\GitHub\\Major_Project\\model_artifacts\\maternal_xgboost.joblib\", \"maternal_xgb\")\n",
    "try_joblib(r\"C:\\Users\\KIIT\\Desktop\\VS_Code\\GitHub\\Major_Project\\model_artifacts\\maternal_scaler.joblib\", \"maternal_scaler\")\n",
    "\n",
    "try_joblib(r\"C:\\Users\\KIIT\\Desktop\\VS_Code\\GitHub\\Major_Project\\model_artifacts\\ctg_randomforest_model.joblib\", \"ctg_rf\")\n",
    "try_joblib(r\"C:\\Users\\KIIT\\Desktop\\VS_Code\\GitHub\\Major_Project\\model_artifacts\\ctg_xgboost_model.joblib\", \"ctg_xgb\")\n",
    "try_joblib(r\"C:\\Users\\KIIT\\Desktop\\VS_Code\\GitHub\\Major_Project\\model_artifacts\\ctg_scaler.joblib\", \"ctg_scaler\")\n",
    "\n",
    "try_keras(r\"C:\\Users\\KIIT\\Desktop\\VS_Code\\GitHub\\Major_Project\\model_artifacts\\fetal_ecg_lstm_model.h5\", \"ecg_lstm\")\n",
    "try_keras(r\"C:\\Users\\KIIT\\Desktop\\VS_Code\\GitHub\\Major_Project\\model_artifacts\\fetal_ultrasound_classifier.h5\", \"us_cnn\")\n",
    "\n",
    "# --- helper to get probability matrix for any model (n_samples, n_classes) ---\n",
    "def model_proba(model, X):\n",
    "    \"\"\"\n",
    "    Return a (n_samples, n_classes) probability array for given model.\n",
    "    Works for sklearn estimators and keras models.\n",
    "    If predict_proba is missing, falls back to predict (one-hot).\n",
    "    \"\"\"\n",
    "    if model is None:\n",
    "        raise ValueError(\"model is None\")\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        return model.predict_proba(X)\n",
    "    # keras model: assume outputs probabilities for multiclass or sigmoid for binary\n",
    "    if hasattr(model, \"predict\"):\n",
    "        p = model.predict(X)\n",
    "        p = np.asarray(p)\n",
    "        # If binary and shape (n,1), convert to two-column probs\n",
    "        if p.ndim == 2 and p.shape[1] == 1:\n",
    "            p = np.concatenate([1 - p, p], axis=1)\n",
    "        # If outputs logits, assume already probabilities\n",
    "        return p\n",
    "    # fallback to predict -> one-hot\n",
    "    preds = np.asarray(model.predict(X))\n",
    "    classes = np.unique(preds)\n",
    "    onehot = np.zeros((len(preds), classes.max() + 1), dtype=float)\n",
    "    onehot[np.arange(len(preds)), preds] = 1.0\n",
    "    return onehot\n",
    "\n",
    "# --- Build maternal modality probability features (train + test) ---\n",
    "maternal_models = []\n",
    "if \"maternal_best_rf\" in loaded: maternal_models.append(loaded[\"maternal_best_rf\"])\n",
    "if \"maternal_xgb\" in loaded: maternal_models.append(loaded[\"maternal_xgb\"])\n",
    "# include rf from notebook if in memory (falls back to loaded or existing variable)\n",
    "try:\n",
    "    # rf may already exist in notebook namespace\n",
    "    if 'rf' in globals() and globals()['rf'] not in maternal_models:\n",
    "        maternal_models.append(globals()['rf'])\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "if len(maternal_models) == 0:\n",
    "    raise RuntimeError(\"No maternal models available for fusion. Ensure maternal_best_rf or maternal_xgboost or rf exist.\")\n",
    "\n",
    "# Prepare train (X_resampled) and test (X_test_scaled) features using saved/available scaler:\n",
    "# prefer loaded scaler, else use existing 'scaler' variable\n",
    "if \"maternal_scaler\" in loaded:\n",
    "    mat_scaler = loaded[\"maternal_scaler\"]\n",
    "else:\n",
    "    mat_scaler = globals().get(\"scaler\", None)\n",
    "\n",
    "if mat_scaler is None:\n",
    "    raise RuntimeError(\"Maternal scaler not found in disk or notebook. Needed to transform tabular maternal features.\")\n",
    "\n",
    "# X_resampled and X_test_scaled should be available in the notebook (from previous cells)\n",
    "X_train_tab = globals().get(\"X_resampled\", None)\n",
    "X_test_tab = globals().get(\"X_test_scaled\", None)\n",
    "y_train_tab = globals().get(\"y_resampled\", None)\n",
    "y_test_tab = globals().get(\"y_true\", None)  # y_true is maternal test labels exposed in notebook\n",
    "\n",
    "if X_train_tab is None or X_test_tab is None or y_train_tab is None or y_test_tab is None:\n",
    "    raise RuntimeError(\"Required variables X_resampled, X_test_scaled, y_resampled, y_true must exist in the notebook.\")\n",
    "\n",
    "# Compute per-model probabilities and concatenate\n",
    "train_probas_parts = []\n",
    "test_probas_parts = []\n",
    "for m in maternal_models:\n",
    "    try:\n",
    "        p_train = model_proba(m, X_train_tab)\n",
    "        p_test = model_proba(m, X_test_tab)\n",
    "    except Exception as e:\n",
    "        # if model expects raw (unscaled) input, try inverse-transform then predict (rare)\n",
    "        raise RuntimeError(f\"Failed to get probabilities from a maternal model: {e}\")\n",
    "    # ensure same number of classes across parts by padding if needed\n",
    "    train_probas_parts.append(p_train)\n",
    "    test_probas_parts.append(p_test)\n",
    "\n",
    "# pad columns so that every part has same number of columns = max_classes\n",
    "max_cols = max(part.shape[1] for part in train_probas_parts + test_probas_parts)\n",
    "def pad_cols(arr, max_cols):\n",
    "    if arr.shape[1] < max_cols:\n",
    "        pad = np.zeros((arr.shape[0], max_cols - arr.shape[1]))\n",
    "        return np.hstack([arr, pad])\n",
    "    return arr\n",
    "\n",
    "train_parts = [pad_cols(p, max_cols) for p in train_probas_parts]\n",
    "test_parts = [pad_cols(p, max_cols) for p in test_probas_parts]\n",
    "\n",
    "X_meta_train = np.hstack(train_parts)\n",
    "X_meta_test = np.hstack(test_parts)\n",
    "\n",
    "print(\"Meta features shape -- train:\", X_meta_train.shape, \"test:\", X_meta_test.shape)\n",
    "\n",
    "# --- Train a simple meta-classifier on concatenated probabilities ---\n",
    "meta = LogisticRegression(multi_class='multinomial', max_iter=2000, solver='lbfgs')\n",
    "meta.fit(X_meta_train, y_train_tab)\n",
    "y_meta_pred = meta.predict(X_meta_test)\n",
    "\n",
    "print(\"Meta fusion results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_tab, y_meta_pred))\n",
    "print(classification_report(y_test_tab, y_meta_pred, digits=4))\n",
    "\n",
    "# Save meta model and note which base models were used\n",
    "joblib.dump({\"meta\": meta, \"base_models\": [\"maternal_best_rf\",\"maternal_xgb\",\"rf\"]}, \"multimodal_fusion_meta.joblib\")\n",
    "print(\"Saved multimodal_fusion_meta.joblib\")\n",
    "\n",
    "# --- Notes / extension points ---\n",
    "# - To incorporate CTG, ECG (LSTM) and Ultrasound models you must provide aligned training samples across modalities.\n",
    "#   For each sample produce per-modality probability vectors (using model_proba), then concatenate similarly\n",
    "#   to X_meta_train/X_meta_test and retrain meta.\n",
    "# - For image model (us_cnn) you can pass arrays of preprocessed images to model_proba(us_cnn, imgs).\n",
    "# - For sequence (ecg_lstm) pass shape (n, timesteps, channels) arrays to model_proba(ecg_lstm, X_seq).\n",
    "# - If modalities have different class orders, ensure consistent class ordering when concatenating probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6092cc11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
